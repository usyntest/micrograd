{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2f9e84b-b3f4-4bb3-970d-802455f14c3a",
   "metadata": {},
   "source": [
    "# Understanding Artificial Neural Networks: Part I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1d2825-650e-4937-b254-c91d131f8f6a",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Artificial Intelligence (AI) is all the hype these days, every other day OpenAI, Google, or Meta is making headlines with a breakthrough in the field, and understanding these breakthroughs is not an easy task. When writing this Meta recently came out with its new LLM architecture Large Concept Models (LCMs). Then why is this blog not about LCMs, some might ask? The answer to that question is _\"Rome wasn't built in a day\"_, so we cannot just jump onto stuff like LLMs, Transformers, CNNs, etc. Artificial Neural Networks set the basis for specialized model architectures like CNN.\n",
    "\n",
    "Artificial Neural Networks (ANNs) are known by several names such as multilayer perceptrons, deep feedforward networks, feedforward neural networks, or just neural networks (NNs). The goal of neural networks is to approximate some function $f^*$ so that we can predict the value of a given set of inputs based on the data provided during the training. Neural networks just like other learning algorithms like linear regression or SVM are just a mathematical function.\n",
    "\n",
    "$$ y = f_{NN}(x)$$\n",
    "\n",
    "\n",
    "The function $f_{NN}$ has a particular form: itâ€™s a nested function. Neural Networks are structures made up of layers of neurons laid out sequentially. Each layer of NN can be thought of as one level of nesting in the $f_{NN}$ function. \n",
    "\n",
    "$$ y = f_{NN} = f_3(f_2(f_1(x)))$$\n",
    "\n",
    "There is a misconception that ANNs try to mimic the human brain or the way it works which is wrong, a better statement would be that ANNs are inspired by the structure of the brain. We don't have enough information on how brains work or function to model it mathematically.\n",
    "\n",
    "**Why use neural networks instead of linear regression?**\n",
    "\n",
    "A neuron can be thought of as a simple mathematical function where inputs are provided and output is received. Every neuron has an activation function which is applied to the input data to get an output.\n",
    "\n",
    "The image shown above is an example of a neuron, as you can see a neuron body is provided with multiple inputs $(x_i)$, and every input is given a weight $(w_i)$. Along with these inputs, there is also a variable bias $(b)$, an activation function is applied to these inputs to get an output.\n",
    "\n",
    "$$ f(x, w, b) = x_1w_1 + x_2w_2 + \\cdots + x_iw_i + b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacced3e-97c9-4b9c-b6b2-f0b62fdfe62e",
   "metadata": {},
   "source": [
    "## What are neural networks?\n",
    "\n",
    "## Neurons\n",
    "\n",
    "## Activation Functions\n",
    "\n",
    "## Layers and Architectures\n",
    "\n",
    "## Forward Propagation\n",
    "\n",
    "## Loss Functions\n",
    "\n",
    "## Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b09160-6e1f-4f3a-88c2-f6f00383c1cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
